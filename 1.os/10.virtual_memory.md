Virtual memory
* technique that allows the execution of processes that are not completely in memory

advantages
* programs can be larger than physical memory

---

**Demand Paging**
* pages are loaded only when they are demanded during program execution

if the process tries to access a page that was not brought into memory, **page fault** occur
* pagin hardware, in translating the address through the page table, will notice that the invalid bit is set, causing a trap to the OS
* procedure of handling trap is straightforward
    1. check internal table in PCB to determine whether reference was a valid or invalid memory access
    2. if reference was invalid
        * terminate the process
        * if valid
            * page in
    3. find a free frame
    4. schedule a secondary storage operation to read the desired page into the newly allocated frame
    5. When the storage read is complete, modify the internal table kept with
the process and the page table to indicate that the page is now in memory
    6. restart the instruction that was interrupted by the trap
* process can now access the page as though it had always been in memory

**pure demand paging**
* start executing a process with no pages in memory
* for every fault happend keep page in

some programs could access several new pages of memory with each instruction execution * (one page for the instruction and many for data)
* causing multiple page faults per instruction
* result in unacceptable system performance
* Programs tend to have **locality of reference** ??? which results in
    * reasonable performance from demand paging

hardware to support demand paging is the same as the hardware for paging and swapping:
* Page table
* Secondary memory (swap device)

A crucial requirement for demand paging is the ability to restart any instruction after a page fault
* OS save the state (registers, condi- tion code, instruction counter) of the interrupted process when the page fault occurs
* it must be able to restart the process in exactly the same place and state
    * except that the desired page is now in memory and is accessible
* Difficulties
    * If a page fault occurs while fetching an operand
        * must fetch and decode the instruction again and then fetch the operand
    * e.g.
        * instruction to ADD the content of A to B, placing the result in C
        * steps to execute the instruction
            1. Fetch and decode the instruction ( ADD )
            2. Fetch A
            3. Fetch B
            4. Add A and B
            5. Store the sum in C
        * if page fault occur at storing in C
            * because C is in a page not currently in memory
        * page in, restrat the instruction
        * restart will require all 5 instruction again
    * e.g.
        * MVC instruction which can move up to 256 bytes form one location to another
        * page fault may occurs at any block (source or destination)
            * after the move is partially done
        * if source and destination blocks overlap, source block may have been modified
        * one cannot simply restart the instruction
        * solution
            * microcode computes and attempts to access both ends of both blocks
                * If a page fault is going to occur, it will happen at this step,  before anything is modified
                * move can then take place
                    * as no page fault can occur, since all the relevant pages are in memory
            * using temporary registers to hold the values of overwritten locations
                * if there is a page fault, all the old values are written back into memory before the trap occurs
                * this action restores memory to its state before the instruction was started, so that the instruction can be repeated
* dempand paging can not be just added to any machine, mnay other difficulties may be there

---

**Free-Frame List**

* most OS maintain a free-frame list, a pool of free frames
* OS typically allocate free frames using a technique known as **zero-fill-on-demand**
    * on-demand, frames are zeroed-out before being allocated
        * thus erasing their previous contents

---

Demand paging can significantly affect the performance of a computer system

---

**copy on write**

Traditionally, fork() worked by
* creating a copy of the parent’s address space for the child
* duplicating the pages belonging to the parent

copy-on-write works by
* allowing the parent and child processes initially to share the same pages
* these shared pages are marked as copy-on-write pages
    * meaning that if either process writes to a shared page, a copy of the shared page is created
* when child process attempts to modify a page set to be copy-on-write
    * OS will obtain a frame from the free-frame list
    * OS create a copy of the page, mapping it to the address space of the child process
    * child process will then modify its copied page
* only the pages that are modified by either process are copied
    * all unmodified pages can be shared by the parent and child processes
* only pages that can be modified need be marked as copy-on-write

<br/>

* `fork()` use copy-on-write
* `vfork()` is provided to not use copy-on-write
    * parent process is suspended
    * child process uses the address space of the parent
    * if the child process changes any pages of the parent’s address space, the altered pages will be visible to the parent once it resumes

---

while page fault, if free-frame list is empty
* instead of temrinating process
* OS combine swapping pages with page replacement to free some frames

### **Page Replacement**

**Basic Page Replacement**
* if no frame is free, find that is not currently being used and free it
* frame can be freed by writing its contents to swap space and
    * changing the page table (and all other tables) to indicate that the page is no longer in memory
* use the freed frame to hold the page for which the process faulted

<br/>

problem
* if frames are not free, two page transfers are required
    * one for the page-out
    * one for the page-in
* it doubles page-fault service time and increases the effective access time

solution
* usign a modify bit (or dirty bit)
* modify bit for a page is set by the hardware whenever any byte in the page is written into
    * indicating that the page has been modified
* if modify bit is set
    * must write to storage
* otherwise
    * no need
* reduce the time required to service a page fault

**frame-allocation algorithm** and **page-replacement algorithm**
* to decide how many frames to allocate to each process
* which frames are to be replaced

---

**FIFO Page Replacement**
* When a page must be replaced, the oldest page is chosen
* performance is not always good
    * page replaced may be an initialization module that was used a long time ago and is no longer needed
    * or it could contain a heavily used variable that was initialized early and is in constant use


**Belady’s anomaly**
* for some page-replacement algorithms, the page-fault rate may increase as the number of allocated frames increases

**LRU Page Replacement**
* associates with each page the time of that page’s last use
* it may require substantial hardware assistance
* implementation ways - counter
    * associate each page-table entry a time-of-use field and
    * add to the CPU a logical clock or counter
    * clock is incremented for every memory reference
    * Whenever a reference to a page is made, contents of the clock register are copied to the time-of-use field in the page-table entry for that page
    * replace the page with the smallest time value when required
    * this scheme requires
        * search of the page table to find the LRU page and
        * a write to memory for each memory access
        * times must also be maintained when page tables are changed (due to CPU scheduling)
        * Overflow of the clock must be considered
* implementation - stack
    * keep a stack of page numbers
    * on page referenced, page is removed from the stack and put on the top
    * most recently used page will always be on top and least used on bottom
    * to removed entries from middle of the stack
        * double linked list may be used
    * each update is lttle more expensive
        * but no seacrh for a replacement

**LRU-Approximation Page Replacement**
* hardware generally do not provide any support for LRU replacement
* many systems provide some help, in the form of a reference bit
* reference bit for a page is set by the hardware whenever that page is reference
    * (either a read or a write to any byte in the page)
    * reference bits are associated with each entry in the page table
* OS sets refrenced bit to 0
    * hardware sets bit to 1 whenever page is referenced
    * examining the reference bits, one an know which pages are used
        * though order can not be known
* **Additional-Reference-Bits Algorithm**
    * ordering information can be record by recording the reference bits at regular intervals
    * e.g.
        * keep 8-bit byte for each page in a table in memory
        * At regular intervals (say, every 100 ms), a timer interrupt transfers control to the OS
        * OS shifts the reference bit for each page into the high-order bit of its 8-bit byte
            * shifting the other bits right by 1 bit and
            * discarding the low-order bit
        * these 8-bit shift registers contain the history of page use for the last eight time periods
        * e.g.
            * 00000000 means page has not been used for eight time periods
            * 11111111 means page is used at least once in each period
            * 11000100 has been used more recently than 01110111
        * on interpreting these 8-bit bytes as unsigned integers
            * page with the lowest number is the LRU page, and it can be replaced
        * numbers are not guaranteed to be unique
            * either swap out all pages with the smallest value or
            * use the FIFO method to choose among them
* **Second-Chance Algorithm**
    * FIFO replacement algorithm which checks only reference bit
    * implementaion - circular queue
* **Enhanced Second-Chance Algorithm**
    * enhance the second-chance algorithm by considering
        * reference bit
        * modify bit as an ordered pair
    * four cases
        1. (0, 0) neither recently used nor modified
            * best page to replace
        2. (0, 1) not recently used but modified
            * not quite as good, because the page will need to be written out before replacement
        3. (1, 0) recently used but clean
            * probably will be used again soon
        4. (1, 1) recently used and modified
            * probably will be used again soon
            * and the page will be need to be written out
    * each page is in one of these four classes
        * for replacement, examine the class and replace the first page encountered in lowest nonempty class
    * reduces I/O

---

Allocation of Frames

> minimum number of frames is defined by the computer architecture

* proportional allocation ???

global replacement
* allows a process to select a replacement frame from the set of all frames, even if that frame is currently allocated to some other process
* generally results in greater system throughput
    * it is therefore the more commonly used method

local replacement
* allows process to select from only its own set of allocated frames

global page-replacement policy ( possible strategy )
* satisfy all memory requests from the free-frame list
* page replacement begins when free-frame list falls below a certain threshold
* it ensures that there is always sufficient free memory to satisfy new requests
* aim is to keep the amount of free memory above a minimum threshold
* when it drops below this threshold
    * a kernel routine is triggered that begins reclaiming pages from all processes in the system (typically excluding the kernel)
* Such kernel routines are often known as **reapers**
* When the amount of free memory reaches the maximum threshold, the reaper routine is suspended, only to resume once free memory again falls below the minimum threshold

In Linux ???
* when the amount of free memory falls to very low levels
* a routine known as the **out-of-memory ( OOM )** killer selects a process to terminate, thereby freeing its memory
* each process has **OOM score**
* process with highest OOM score is selected for termination

```bash
$ cat /proc/20125/oom_score
303
```
---

major page fault
* occurs when a page is referenced and the page is not in memory

minor page faults
* occur when a process does not have a logical mapping to a page, yet that page is in memory
* can occur for one of two reasons
    1. process may reference a shared library that is in memory, but the process does not have a mapping to it in its page table
        * In this instance, it is only necessary to update the page table to refer to the existing page in memory
    2. when a page is reclaimed from a process and placed on the free-frame list, but the page has not yet been zeroed out and allocated to another process
        * the frame is removed from the free-frame list and reassigned to the process

```bash
$ ps -eo min_flt,maj_flt,cmd | (head -1 ; tail -4)
 MINFL  MAJFL CMD
   148      0 /bin/bash
   299      0 /usr/lib/evince/evinced
 10909      0 /bin/bash
   312      0 /usr/lib/dconf/dconf-service
```

---

**Thrashing** ???
* high paging activity is called thrashing
* aprocess is thrashing if it is spending more time paging than executing

locality ???

---

