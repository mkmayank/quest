Critical-Section Problem
* is to design a protocol that the processes can use to synchronize their activity so as to cooperatively share data

A solution to the critical-section problem must satisfy the following three
requirements:

1. Mutual exclusion
    * If process P i is executing in its critical section, then no other processes can be executing in their critical sections.

2. Progress
    * If no process is executing in its critical section and some processes wish to enter their critical sections, then only those processes that are not executing in their remainder sections can participate in deciding which will enter its critical section next, and this selection cannot be postponed indefinitely

3. Bounded waiting
    * There exists a bound, or limit, on the number of times that other processes are allowed to enter their critical sections after a process has made a request to enter its critical section and before that request is granted

---

Hardware support for synchronization:
* Memory Barriers
    * system may reorder instructions, a policy that can lead to unreliable data states
    * To address this issue, computer architectures provide instructions that can force any changes in memory to be propagated to all other processors
        * thereby ensuring that memory modifications are visible to threads running on other processors
    * Such instructions are known as **memory barriers** or memory fences
    * When a memory barrier instruction is performed, the system ensures that all loads and stores are completed before any subsequent load or store operations are performed
    * Therefore, even if instructions were reordered, the memory barrier ensures that the store operations are completed in memory and visible to other processors before future load or store operations are performed
    * memory barriers are considered very low-level operations and are typically only used by kernel developers when writing specialized code that ensures mutual exclusion

* Hardware instructions

* atomic variables

---

Mutex Locks
The hardware-based solutions to the critical-section problem presented in Sec-
tion 6.4 are complicated as well as generally inaccessible to application pro-
grammers. Instead, operating-system designers build higher-level software
tools to solve the critical-section problem. The simplest of these tools is the
mutex lock. (In fact, the term mutex is short for mutual exclusion.) We use the
mutex lock to protect critical sections and thus prevent race conditions. That
is, a process must acquire the lock before entering a critical section; it releases
the lock when it exits the critical section. The acquire() function acquires the
lock, and the release() function releases the lock, as illustrated in Figure 6.10.
A mutex lock has a boolean variable available whose value indicates if
the lock is available or not. If the lock is available, a call to acquire() succeeds,
and the lock is then considered unavailable. A process that attempts to acquire
an unavailable lock is blocked until the lock is released.
The main disadvantage of the implementation given here is that it requires
busy waiting. While a process is in its critical section, any other process that
tries to enter its critical section must loop continuously in the call to acquire() .
This continual looping is clearly a problem in a real multiprogramming system,
where a single CPU core is shared among many processes. Busy waiting also
wastes CPU cycles that some other process might be able to use productively.
(In Section 6.6, we examine a strategy that avoids busy waiting by temporarily
putting the waiting process to sleep and then awakening it once the lock
becomes available.)
The type of mutex lock we have been describing is also called a spin-
lock because the process “spins” while waiting for the lock to become avail-
able. (We see the same issue with the code examples illustrating the com-
pare and swap() instruction.) Spinlocks do have an advantage, however, in
that no context switch is required when a process must wait on a lock, and a
context switch may take considerable time. In certain circumstances on multi-
core systems, spinlocks are in fact the preferable choice for locking. If a lock is
to be held for a short duration, one thread can “spin” on one processing core
while another thread performs its critical section on another core. On modern
multicore computing systems, spinlocks are widely used in many operating
systems.
In Chapter 7 we examine how mutex locks can be used to solve classical
synchronization problems. We also discuss how mutex locks and spinlocks are
used in several operating systems, as well as in Pthreads.